{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Learning configuration for the autoregressive Lorenz emulator\n",
    "\n",
    "This notebook assumes that you already went over the `lorenz_emulator.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "import equinox as eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainax as tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_data_trj = tx.sample_data.lorenz_rk4(num_samples=9, key=jax.random.PRNGKey(0))\n",
    "# (num_trjs, num_steps, num_dofs=3)\n",
    "lorenz_data_trj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_stepper = tx.sample_data.make_lorenz_stepper_rk4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.allclose(lorenz_data_trj[0, 1], lorenz_stepper(lorenz_data_trj[0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing all 9 trajectories at once reveals that they are all quite similar\n",
    "caused by being around the chaotic attractor the Lorenz equation is known for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, subplot_kw={\"projection\": \"3d\"}, figsize=(12, 12))\n",
    "\n",
    "STEPS_TO_PLOT = -1\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(\n",
    "        lorenz_data_trj[i, :STEPS_TO_PLOT, 0],\n",
    "        lorenz_data_trj[i, :STEPS_TO_PLOT, 1],\n",
    "        lorenz_data_trj[i, :STEPS_TO_PLOT, 2],\n",
    "        lw=1.0,\n",
    "        color=\"blue\",\n",
    "        label=\"Reference\",\n",
    "    )\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(-30, 30)\n",
    "    ax.set_zlim(0, 50)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the values of the three variables over time for all the 9 trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(12, 5))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(lorenz_data_trj[i], label=[\"X\", \"Y\", \"Z\"])\n",
    "    ax.set_title(f\"Trajectory {i}\")\n",
    "    ax.set_ylim(-25, 50)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sanity check that the trajectories are free from diverged values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the presence of NaNs\n",
    "jnp.any(jnp.isnan(lorenz_data_trj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Steps Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator = eqx.nn.MLP(3, 3, 60, 6, jax.nn.relu, key=jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_5_trainer = tx.trainer.SupervisedTrainer(\n",
    "    lorenz_data_trj,\n",
    "    optimizer=optax.adam(1e-4),\n",
    "    num_training_steps=20_000,\n",
    "    batch_size=64,\n",
    "    num_rollout_steps=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_5_trained_emu, sup_5_loss_history = sup_5_trainer(emulator, jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_5_emulator_trj = jax.vmap(\n",
    "    rollout(sup_5_trained_emu, lorenz_data_trj.shape[1] - 1, include_init=True)\n",
    ")(lorenz_data_trj[:, 0, :])\n",
    "sup_5_emulator_trj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, subplot_kw={\"projection\": \"3d\"}, figsize=(12, 12))\n",
    "\n",
    "STEPS_TO_PLOT = -1\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(\n",
    "        sup_5_emulator_trj[i, :STEPS_TO_PLOT, 0],\n",
    "        sup_5_emulator_trj[i, :STEPS_TO_PLOT, 1],\n",
    "        sup_5_emulator_trj[i, :STEPS_TO_PLOT, 2],\n",
    "        lw=1.0,\n",
    "        color=\"red\",\n",
    "        label=\"Emulator\",\n",
    "    )\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(-30, 30)\n",
    "    ax.set_zlim(0, 50)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Steps Diverted Chain Training\n",
    "\n",
    "The emulator is a simple MLP with 60 hidden units and 6 hidden layers together\n",
    "with the ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer object is the highest level interface to `Trainax`. It combines\n",
    "sampling across the trajectories with a loss configuration (here one-step\n",
    "supervised learning) and the iterative nature of network training.\n",
    "\n",
    "Note the notion of `num_training_steps`. We do not specify the number of epochs\n",
    "but work solely in terms of how often the network weights will be updated.\n",
    "Internally, the trainer will determine the number of epochs necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_one_5_trainer = tx.trainer.DivertedChainBranchOneTrainer(\n",
    "    lorenz_data_trj,\n",
    "    optimizer=optax.adam(1e-4),\n",
    "    num_training_steps=20_000,\n",
    "    batch_size=64,\n",
    "    num_rollout_steps=5,\n",
    "    ref_stepper=lorenz_stepper,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer is now a callable object which takes an initial state of the\n",
    "emulator (which comes from the initialization of the network) and a jax random\n",
    "key to kickstart the stochastic minibatching. It then returns the trained\n",
    "instance of the emulator (with the modified weights) as well as an array\n",
    "containing the loss values over the training steps.\n",
    "\n",
    "For the training a tqdm progress meter is spawned to visualize the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_one_5_trained_emu, div_one_5_loss_history = div_one_5_trainer(\n",
    "    emulator, jax.random.PRNGKey(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loss sufficiently decreased over the training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(div_one_5_loss_history)\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.ylabel(\"Train Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Emulator\n",
    "\n",
    "We will evaluate the emulator on the same trajectories as it was trained. This\n",
    "is not an issue because we will test for **temporal generalization**, i.e., for\n",
    "how many steps it can correctly autoregressively predict into the future and if\n",
    "it is able to reproduce certain properties of the Lorenz attractor.\n",
    "\n",
    "The below rollout transformation is an efficient routine to autoregressively run\n",
    "the emulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(stepper, n, *, include_init: bool = False):\n",
    "    def scan_fn(u, _):\n",
    "        u_next = stepper(u)\n",
    "        return u_next, u_next\n",
    "\n",
    "    def rollout_fn(u_0):\n",
    "        _, trj = jax.lax.scan(scan_fn, u_0, None, length=n)\n",
    "\n",
    "        if include_init:\n",
    "            return jnp.concatenate([jnp.expand_dims(u_0, axis=0), trj], axis=0)\n",
    "\n",
    "        return trj\n",
    "\n",
    "    return rollout_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_1_emulator_trj = jax.vmap(\n",
    "    rollout(div_one_5_trained_emu, lorenz_data_trj.shape[1] - 1, include_init=True)\n",
    ")(lorenz_data_trj[:, 0, :])\n",
    "sup_1_emulator_trj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the first 20 steps of emulator and simulator next to each other.\n",
    "\n",
    "They diverge over the steps which is expected due to the chaotic nature of the\n",
    "Lorenz equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "TRJ_INDEX = 0\n",
    "STEPS_TO_PLOT = 20\n",
    "ax.plot(\n",
    "    lorenz_data_trj[TRJ_INDEX, :STEPS_TO_PLOT, 0],\n",
    "    lorenz_data_trj[TRJ_INDEX, :STEPS_TO_PLOT, 1],\n",
    "    lorenz_data_trj[TRJ_INDEX, :STEPS_TO_PLOT, 2],\n",
    "    lw=1.0,\n",
    "    color=\"blue\",\n",
    "    label=\"Reference\",\n",
    ")\n",
    "ax.plot(\n",
    "    sup_1_emulator_trj[TRJ_INDEX, :STEPS_TO_PLOT, 0],\n",
    "    sup_1_emulator_trj[TRJ_INDEX, :STEPS_TO_PLOT, 1],\n",
    "    sup_1_emulator_trj[TRJ_INDEX, :STEPS_TO_PLOT, 2],\n",
    "    lw=1.0,\n",
    "    color=\"red\",\n",
    "    label=\"Emulator\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_xlim(-20, 20)\n",
    "ax.set_ylim(-30, 30)\n",
    "ax.set_zlim(0, 50)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This divergence is visible across all trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, subplot_kw={\"projection\": \"3d\"}, figsize=(12, 12))\n",
    "\n",
    "STEPS_TO_PLOT = 20\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(\n",
    "        lorenz_data_trj[i, :STEPS_TO_PLOT, 0],\n",
    "        lorenz_data_trj[i, :STEPS_TO_PLOT, 1],\n",
    "        lorenz_data_trj[i, :STEPS_TO_PLOT, 2],\n",
    "        lw=1.0,\n",
    "        color=\"blue\",\n",
    "        label=\"Reference\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        sup_1_emulator_trj[i, :STEPS_TO_PLOT, 0],\n",
    "        sup_1_emulator_trj[i, :STEPS_TO_PLOT, 1],\n",
    "        sup_1_emulator_trj[i, :STEPS_TO_PLOT, 2],\n",
    "        lw=1.0,\n",
    "        color=\"red\",\n",
    "        label=\"Emulator\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        lorenz_data_trj[i, 0, 0],\n",
    "        lorenz_data_trj[i, 0, 1],\n",
    "        lorenz_data_trj[i, 0, 2],\n",
    "        color=\"black\",\n",
    "        label=\"Initial\",\n",
    "    )\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(-30, 30)\n",
    "    ax.set_zlim(0, 50)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a very long trajectory of 1000 steps produced by the emulator.\n",
    "A good emulator would produce plots which are similar to the ones we saw by the\n",
    "simulator earlier. However, it is clearly visible that the emulator is only\n",
    "partially capable of reproducing the Lorenz attractor.\n",
    "\n",
    "For some trajectories, the visual match is quite good. Some trajectories favor\n",
    "one side of the attractor more than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, subplot_kw={\"projection\": \"3d\"}, figsize=(12, 12))\n",
    "\n",
    "STEPS_TO_PLOT = -1\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(\n",
    "        sup_1_emulator_trj[i, :STEPS_TO_PLOT, 0],\n",
    "        sup_1_emulator_trj[i, :STEPS_TO_PLOT, 1],\n",
    "        sup_1_emulator_trj[i, :STEPS_TO_PLOT, 2],\n",
    "        lw=1.0,\n",
    "        color=\"red\",\n",
    "        label=\"Emulator\",\n",
    "    )\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(-30, 30)\n",
    "    ax.set_zlim(0, 50)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be seen in the temporal plots of all three variables. The\n",
    "trajectories in which one side is favored are the ones in which the emulator\n",
    "seems to enter a dead end after some time.\n",
    "\n",
    "However, across all trajectories, the emulator seems to understand that the\n",
    "green curve (corresponding to the z variable) is always positive and hence above\n",
    "blue (x) and orange (y). It also understands that the x and y variables are\n",
    "always very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(12, 5))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(sup_1_emulator_trj[i], label=[\"X\", \"Y\", \"Z\"])\n",
    "    ax.set_title(f\"Trajectory {i}\")\n",
    "    ax.set_ylim(-25, 50)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completion, let's also compute the error rollout across all trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_loss = tx.loss.Normalized_MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_1_error_trj = jax.vmap(nmse_loss, in_axes=1)(sup_1_emulator_trj, lorenz_data_trj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is a very strong error growth over time. Hence, we cannot\n",
    "just judge the emulator's quality in this direct comparison against the\n",
    "reference trajectories.\n",
    "\n",
    "Still, it is able to mimic the RK4 simulator very closely for the first 10 steps\n",
    "and the difference is still acceptable until 40 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sup_1_error_trj[:50])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Mean normalized MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs-recent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
